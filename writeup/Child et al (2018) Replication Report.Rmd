---
title: "Replication of Experiment 1 by Child, Oakhill, & Garnham (2018, Language, Cognition and Neuroscience)"
author: "Madison Bunderson (mebund@stanford.edu)"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    toc: yes
    toc_depth: 3
    toc_float:
      collapsed: false
---

<!-- Replication reports should all use this template to standardize reporting across projects.  These reports will be public supplementary materials that accompany the summary report(s) of the aggregate results. -->

## Introduction

### Experiment Overview and Choice Justification

In Experiment 1 of the manuscript "You're the emotional one: the role of perspective for emotion processing in reading comprehension", Child, Oakhill, & Garnham (2018) manipulated the perspective (personal versus onlooker) and overall valence (positive versus negative) of short text passages to investigate the potential effects on a reader's speed and emotional response. Overall, the researchers found that participants read more quickly in the personal perspective condition. Additionally, they found that in the positively valenced condition, personal perspective induced faster reading per sentence and more positive feelings after reading. In the negatively valenced condition, there were no evident effects of perspective on reading speed or emotional response. I aim to replicate these findings in the current project. 

I selected this study because the influence of perspective on the reading experience is one that relates to my own future research within the science of reading, as I intend to examine processing of text and its relation to engagement and comprehension. I am particularly intrigued by the idea of text manipulation as a tool to influence reader behavior, given it may hold implications for educational practice. 

### Required Stimuli and Expected Procedures

Participants were recruited utilizing Amazon's Mechanical Turk (MTurk), an online crowdsourcing platform. All participants were compensated for their time.

Following an introduction and three practice trials, participants were shown 48 randomized passages that varied in length from 5 to 9 sentences. Each passage was presented sentence-by-sentence, and the amount of time that it took for the participant to read each sentence was recorded. 24 of the total passages were experimentally manipulated passages, provided by the original authors in their [supplemental material](https://github.com/psych251/child2018/blob/master/original_paper/Child_Oakhill_Garnham_2018_Supplemental.pdf); the passages were counterbalanced for perspective (personal versus onlooker), valence (positive versus negative), and character gender. The other 24 passages were distractor passages, written in third or first person with the intention of concealing the purpose of the experiment. All text was presented with identical font size and color (black) on a white background. Following the presentation of the final sentence of each passage, participants responded with a rating of their current emotional state on a scale of 1 (negative) to 10 (positive). Two-second breaks were given between emotional response ratings and the presentation of the first sentence of the next passage.

### Anticipated Challenges

I believe my primary challenge will be the programming of the experiment due to the number of passage stimuli, the fact that they are presented sentence-by-sentence, and the need to collect reaction time data. I do not have previous experience with Javascript, having primarily used tools like Qualtrics and E-prime in the past. Qualtrics does have a timing feature that could be applied to this paradigm, but I'm unsure if its sensitivity is appropriate for the current task. Furthermore, I am also new to utilizing the tidyverse for data work, and therefore expect that there will be a learning curve during my analyses. Lastly--although I hope that this will not present a challenge--I will need to obtain the 24 distractor passages described above as they are not included in the supplemental material.

### Related Links

The GitHub project repository for this replication can be found [here.](https://github.com/psych251/child2018)

The original paper being replicated can be found [here.](https://github.com/psych251/child2018/blob/master/original_paper/Child_Oakhill_Garnham_2018.pdf)

<!-- This is the end of the introduction section. -->

## Methods

### Power Analysis

The calculated power for the original study, utilizing the simr package, was 13% for the reading times linear mixed effects model, and 16% for the emotion self-rating linear mixed effects model. Because the study will be unable to reach 80% power, the planned sample size will be calculated based off of course budgetary restrictions. Furthermore, the key analysis of interest was revised in order to select a statistical test (the T-test, also reported in the original paper) that was more likely to be powered adequately.

### Planned Sample

The original experiment's participants were 36 native speakers of English with an age range of 18 to 33 years. Participants with reading disorders were excluded.

In line with the original study, the current study will aim to collect data from approximately 30 participants (**note**: this will be modified to maximize the sample size while working within the constraints of the course budget).  Participants will be limited in order to include only native speakers of English and those without a diagnosed reading disorder. These exclusions will be listed in the description of the task on MTurk. Additionally, screening questions will be built into the survey on Qualtrics such that if someone indicates that they are not a native English speaker and/or have been diagnosed with a reading disorder, the survey will then terminate. 

### Materials

The original experiment utilized 48 novel passages of 5-9 sentences, counterbalanced to account for valence, perspective, and gender (in the third-person perspective passages). Each passage ended with an explicit emotion word that matched the content of the earlier sentences in each passage. These passages were provided in the [supplemental material](https://github.com/psych251/child2018/blob/master/original_paper/Child_Oakhill_Garnham_2018_Supplemental.pdf) of the original paper. To further detail the composition of these materials, there were:

a. 24 passages written in the second-person perspective (12 of which were positively-valenced and 12 of which were negatively-valenced),
b. 12 passages written in the third-person perspective featuring a female character (6 of which were positively-valenced and 6 of which were negatively-valenced), and 
c. 12 passages written in the third-person perspective featuring a male character (6 of which were positively-valenced and 6 of which were negatively-valenced). 

It is of note that there were only 24 novel situations across passage stimuli, such that second-person and third-person perspectives were written about the same scenario but with modified language. 

Additionally, participants were presented with 24 [distractor (also referred to as filler) passages](https://github.com/psych251/child2018/blob/master/original_paper/Child_Oakhill_Garnham_2018_Supplemental_Filler.pdf) to help disguise the purpose of the experiment. Filler passages were comprised of passages of similar length as the experimental passages, and utilized a mixture of first-person and third-person perspective. Another noted difference is that "in contrast to the experimental items, the final sentence of the fillers did not contain an explicit emotion and the texts were therefore more ambiguous" (Child, Oakhill, & Garnham, 2018).

These passages were utilized in the current replication in mostly original form, with small changes made to spelling to accommodate for linguistic differences between British English and American English. One such example is the changing of 'pay-cheque' to 'paycheck'. 

Additional materials that were sought out from the original authors were the instructions and practice trials, as well as the exact wording of the question that asked participants to self-rate their current emotional state. The first author did not respond to provide these materials, and the other authors were not able to access them. Thus, the current replication attempted to create the instructions, practice trials, and emotion self-rating question in a way that was most authentic to the details provided in the original experiment's manuscript.

### Procedure	

In the original experiment,

> "[a]fter an introduction and three practice trials, the main text passages were presented sentence-by-sentence. After having read the final sentence, participants typed in their self-rating i.e. the number rating their own emotion. After the response, the next trial began following a two second break" (Child, Oakhill, & Garnham, 2018). 

The 48 total passages were presented in random order for every participant, with counterbalancing for perspective, valence and gender of character. Reaction time was collected on a sentence-by-sentence basis. The experiment was originally presented utilizing E-Prime software. Appearance-wise, it is of note that the text was presented on a white background with a size 24 black font. 

The above procedure of the original experiment was followed very closely. There were two procedural deviations: 

1. The participant clicked on the number to rate their own emotion, rather than typing it in on their own keyboard, and
2. The experiment was implemented using Qualtrics rather than E-prime, as previously mentioned.

The completed Qualtrics paradigm is linked [here](https://stanforduniversity.qualtrics.com/jfe/form/SV_9sLrDIEvPE0mXel). Please note that this link is to the pilot survey, rather than the actual implemented survey, to prevent erroneous data collection. There were no differences between this pilot and the final implemented experiment. 

### Analysis Plan

As in the original article, reading time data will be analyzed on a sentence-by-sentence basis (rather than collated per passage). To clean the data, filler passages must first be removed from the data. Then, outliers above or below 2.5 standard deviations of the mean reading times per sentence will be removed on a per-participant basis. Means will then be recalculated using the remaining items. A natural log transformation will then be used to normalize the reaction time data (unless data presents normally); length effects will then be controlled for from participant-to-participant by regressing reading times against the number of characters per sentence. 

**The revised key analysis of interest** given power constraints and as discussed with the teaching team is a replication of the T-test statistics listed in the original paper. One T-test was reported for the influence of perspective on reading times in positive passages, and one T-test was given for the impact of perspective on emotion self-rating in positive passages. Although not the main analysis of the original paper, this statistic was more likely to be reasonably powered with the course sample constraints.

An exploratory analysis has been planned regarding the original analysis of interest, which was avoided due to issues with power. Due to this power issue The original key analysis was a linear mixed effects (LME) model, repeated for reading times and then emotion ratings. For examining both outcomes of interest, perspective and valence were included as fixed-effects, with participants and items as random intercepts. In the original analysis, random slopes were not included in either model due to low scores on the Akaike Information Criterion (AIC); this will also be followed in the replication. 


### Differences from Original Study

Differences between the original study and the current study have been minimized, but those present are summarized below:

The participant sample will differ in that it will be collected online through MTurk utilizing a Qualtrics survey, rather than in-person utilizing E-prime software. Despite this change, the experimental design of the original setup is completely replicable using the Qualtrics software. Reaction time data and emotional ratings will still be obtained as they were in the original design, and clicking (rather than typing) the emotional rating will not have any impact as reaction time during emotion rating is irrelevant to the aims of the study. One concern of note is that reaction time data is sensitive to participant distraction, and external distraction is arguably more present when a survey is completed in a participant's personal setting rather than in a laboratory. However, extended reaction times due to distraction will likely be addressed utilizing the cleaning method detailed in the analysis plan, so the impact of this difference is expected to be minimized.

Furthermore, the sample will be drawn from a pool of American participants, rather than British participants. As the author makes claims regarding readers in general, rather than readers in the United Kingdom alone, this should not impact the claims of the paper; however, this is recognized as a limitation. To accommodate the difference in geographic location, passage stimuli were modified to change British English spellings to American English spellings. This change was made to reduce any distraction that may have been caused by the less commonly encountered spelling; however, it does not impact the meaning of the word, nor does it change the key elements of the passage (the perspective or emotion). Therefore this difference is not expected to impact the claims made by the original paper.

Lastly, the first author did not respond to communications and only the filler passages were able to be obtained from the senior author. Because of his, the instructions, practice trials, and wording of the emotion self-rating question were all generated anew for the current replication. Feedback was obtained during piloting to ensure that the instructions and practice trials prepared participants for the task; however, it is impossible to know whether changes in wording here or in the emotion self-rating question will impact results. Although each material has been re-created in order to best achieve its original aim, there is a possibility that the wording of the emotion self-rating question may impact response, and thus impact the replication of the second model of this paper.

### Methods Addendum (Post Data Collection)

You can comment this section out prior to final report with data collection.

#### Actual Sample
  Sample size, demographics, data exclusions based on rules spelled out in analysis plan

#### Differences from pre-data collection methods plan
  Any differences from what was described as the original plan, or “none”.


## Results


### Data preparation

Raw data was cleaned to remove additional columns collected by Qualtrics that were unnecessary for analyses, as well as the filler passages (denoted with the "FILLER" tag in the column heading). Means were calculated for reading time per sentence, and any sentence that had a reaction time above or below 2 standard deviations of the mean was excluded. Means were then recalculated following these exclusions. A natural log transformation was performed to normalize the data, and length effects were controlled for by regressing each sentence's reading time against the number of characters in that sentence. Two additional columns were then created; one to represent the perspective condition (second-person versus third person) and one to represent the valence condition (positive versus negative).

Some notes for interpreting the raw data column headings:

a. '2p' stands for second-person perspective.
b. '3pF' stands for third-person perspective with a female character.
c. '3pM' stands for third-person perspective with a male character.
d. 'P' and 'N', followed by a number, indicate the valence and scenario number. 
e. 'RT' stands for reaction or reading time, and is preceded by a number indicating sentence.
f. 'ER' stands for emotion self-rating.

*In accordance with the above notes, column titles were represented in three part annotations structured with the perspective, valence and scenario, and value indicator (for either sentence reaction time or emotion rating). One example is '2p.P1.1RT', meaning that the passage was written in second-person about the first positive scenario, and that the value logged in that column is the reaction time for the first sentence. Another example is '3pF.N5.ER', indicating that the passage was written in third-person perspective (with a female character) about the fifth negative scenario, and that the value logged in that column is the emotion rating for that passage.* 

The above data preparation process is hidden code below. Data files can be found in the [data](https://github.com/psych251/child2018/tree/master/data) folder of the Github repository.

```{r include=F}
###Data Preparation

####Load Relevant Libraries and Functions

library(tidyverse)
library(RCurl) #for url import of data
library(rstatix) 
library(lme4)


####Import data from Qualtrics and Excel (Character Count Info)

child2018rep_data_link <- getURL("https://raw.githubusercontent.com/psych251/child2018/master/data/psych251_child2018_anonymized_pilotA.csv")
child2018rep_data <- read.csv(text = child2018rep_data_link)

child2018rep_charcount_link <- getURL("https://raw.githubusercontent.com/psych251/child2018/master/data/Child_Oakhill_Garnham_2018_Sentence_CharacterCount.csv")
child2018rep_charcount <- read.csv(text = child2018rep_charcount_link)

#### Data exclusion / filtering

filtered_data = child2018rep_data %>%
  filter(StartDate!="Start Date" & EndDate != '{"ImportId":"endDate","timeZone":"America/Denver"}') %>%
  filter(D2.NATIVE.ENGLISH==1 & D3.READING.DISORDER==2) %>%
  select(-c("StartDate", "EndDate", "Status", "Progress", "Finished", "RecordedDate", "ResponseId", "DistributionChannel", "UserLanguage", "Duration..in.seconds.", "D2.NATIVE.ENGLISH", "D3.READING.DISORDER"),
         -starts_with("FILLER"),
         -starts_with("PRACTICE"),
         -contains("First.Click"),
         -contains("Last.Click"),
         -contains("Click.Count")) %>%
  rename("Subject" = "mTurk",
         "Age" = "D1.AGE") %>%
  relocate("Subject", .before = "Age") %>%
  rename_all(~str_replace_all(., "_Page.Submit", ""))  %>%
  rename_all(~str_replace_all(., "X", ""))

#### Prepare data for analysis - create columns etc.
#### RT analysis data preparation--survey data

RT_data = filtered_data %>%
  select(-contains("ER"))

long_RT_data = RT_data %>% 
  pivot_longer(cols=-c("Subject", "Age"),
               names_to = 'Passage',
               values_to = 'RT') %>%
  filter(Passage!="Subject.1" & Passage!="Age.1") %>%
  mutate(Perspective = grepl("2p", Passage),
         Valence = grepl(".P", Passage))

#### RT analysis data prep--merging in the character count data and converting to correct format

long_RT_data <- left_join(long_RT_data, child2018rep_charcount, by = c("Passage"))

long_RT_data = long_RT_data %>%
  select(-contains("Text"))

long_RT_data$Subject <- as.factor(long_RT_data$Subject)
long_RT_data$Age <- as.numeric(long_RT_data$Age)
long_RT_data$RT <- as.numeric(long_RT_data$RT)
long_RT_data$Perspective <- as.logical(long_RT_data$Perspective)
long_RT_data$Valence <- as.logical(long_RT_data$Valence)
long_RT_data$Character_Count <- as.numeric(long_RT_data$Character_Count)

#### ER analysis data preparation
ER_data = filtered_data %>%
  select(-contains("RT"))

long_ER_data = ER_data %>%
  pivot_longer(cols = -c("Subject", "Age"),
               names_to = 'Passage',
               values_to = 'ER') %>%
  filter(Passage!="Subject.1" & Passage!="Age.1") %>%
  mutate(Perspective = grepl("2p", Passage),
         Valence = grepl(".P", Passage))

long_ER_data$Subject <- as.factor(long_ER_data$Subject)
long_ER_data$Age <- as.numeric(long_ER_data$Age)
long_ER_data$ER <- as.numeric(long_ER_data$ER)
long_ER_data$Perspective <- as.logical(long_ER_data$Perspective)
long_ER_data$Valence <- as.logical(long_ER_data$Valence)

```

### Confirmatory analysis

Prior to producing the final models, the mean and standard deviation for age needed to be calculated. For the reading times model, data above or below 2.5 standard deviations of the mean needed to be excluded. It was unclear in the original paper if means were calculated overall, or grouped, so below they are calculated overall. A natural log transformation was performed on the RT data, along with a regression of reading times against characters per sentence. Means and standard deviations were then calculated for the emotion rating model.  This code is presented below:

```{r}
####overall sample age descriptives
long_ER_data %>%
  summarise(Mean_Age = mean(Age, na.rm = T),
            StdDev_Age = sd(Age, na.rm = T),
            Range_Age = paste(min(Age, na.rm = T), "-", max(Age, na.rm = T)),
            n = sum(!is.na(Age)))

####RT analysis: exclusions based on outliers and means and SDs of remaining

long_filtered_RT_data = long_RT_data %>%
  filter(between(RT, mean(RT, na.rm=TRUE) - (2.5 * sd(RT, na.rm=TRUE)), 
                     mean(RT, na.rm=TRUE) + (2.5 * sd(RT, na.rm=TRUE))))

long_filtered_RT_data %>%
  group_by(Perspective, Valence) %>%
  summarise(Mean_RT = mean(RT, na.rm=T),
            StdDev_RT = sd(RT, na.rm=T))

####RT analysis: normality checks, log transformation, normality checks

long_filtered_RT_data %>% 
  shapiro_test(RT)

long_filtered_RT_data$ln_RT <- log(long_filtered_RT_data$RT)

long_filtered_RT_data %>% 
  shapiro_test(ln_RT)

####RT analysis: regression of ln_RT against characters per sentence and creation of residuals

regression_RT_data = lmer(ln_RT ~ 1 + Character_Count + (1 + Character_Count | Subject), long_filtered_RT_data)

long_filtered_RT_data$ln_RT_Resid = residuals(regression_RT_data)

```

Below is the code for the histogram of the log-transformed reading times, followed by Figure 1 from the original paper representing the same data. Note that "true" for perspective is second person, whereas "true" for valence is positive. 

```{r}
RT_data_graph = long_filtered_RT_data %>%
  group_by(Perspective, Valence) %>%
  summarise(Mean_lnRTResid = mean(ln_RT_Resid, na.rm=T),
            SE_RT = sqrt(sum(residuals(regression_RT_data)^2) / df.residual(regression_RT_data)))

ggplot(RT_data_graph, aes(x=Valence, y=Mean_lnRTResid, fill=Perspective)) +
  geom_bar(position="dodge", stat="identity") +
  geom_errorbar(aes(ymin=Mean_lnRTResid-SE_RT, ymax=Mean_lnRTResid+SE_RT), width = .5, position=position_dodge(.9), na.rm=T)  +
  ylim(-0.050, 0.050) +
  labs(title="Reading Times for Valence by Perspective", y="Log Residual Reading Times", x = "Valence") +
  scale_x_discrete(labels=c("FALSE"="Negative", "TRUE"="Positive")) +
  scale_fill_discrete(name="Perspective", labels = c("Third-person (he/she)", "Second-person (you)"))

####not clear in original data what they used for error bars when plotting the residuals of the ln-RTs...

knitr::include_graphics("https://github.com/psych251/child2018/blob/master/original_paper/Child_Oakhill_Garnham_2018_Figure1.png?raw=true")
```

Below is the code for the histogram of the emotion ratings data, followed by Figure 2 from the original paper representing the same data. Note that "true" for perspective is second-person, whereas "true" for valence is positive.

```{r}
ER_data_graph = long_ER_data %>% 
  group_by(Perspective, Valence) %>%
  summarise(Mean_ER = mean(ER, na.rm=T),
            StdDev_ER = sd(ER, na.rm=T),
            SE_ER = sd(ER, na.rm=T)/sqrt(length(ER[!is.na(ER)])))


ggplot(ER_data_graph, aes(x=Valence, y=Mean_ER, fill=Perspective)) +
  geom_bar(position="dodge", stat="identity") +
  geom_errorbar(aes(ymin=Mean_ER-SE_ER, ymax=Mean_ER+SE_ER), width = .5, position=position_dodge(.9), na.rm=T) +
  labs(title="Self-rated Emotions for Valence by Perspective", y="Self-rated Emotion", x = "Valence") +
  scale_x_discrete(labels=c("FALSE"="Negative", "TRUE"="Positive")) +
  scale_fill_discrete(name="Perspective", labels = c("Third-person (he/she)", "Second-person (you)"))

knitr::include_graphics("https://github.com/psych251/child2018/blob/master/original_paper/Child_Oakhill_Garnham_2018_Figure2.png?raw=true")
```

As specified earlier, due to power constraints replication of an alternative primary statistic, the T-test, was explored as the key analysis of interest.

The original value for the T-test examining the impact of perspective on reading time in positive passages was t(4408)=3.73, p < .001. The current replication's T-test is reported below:

```{r}
RT_T_test <- long_filtered_RT_data %>%
  t_test(Valence ~ Perspective) %>%
  add_significance()

RT_T_test
```

The original value for the T-test examining the impact of perspective on emotion-self rating in positive passages was t(4335)=3.67, p < .001. The current replication's T-test is reported below:

```{r}
ER_T_test <- long_ER_data %>%
  t_test(Valence~Perspective) %>%
  add_significance()

ER_T_test
```

### Exploratory analyses

Exploratory analyses were run with regards to the main analyses of the original paper. Two linear mixed effects (LME) models were run; one for reading times, and one for emotion ratings. For both models, perspective and valence were included as fixed-effects, and participants and items were included as random intercepts. Below is the code for running these models:

```{r}
##still working on this as of 10/18/20

RT_model <- lmer(ln_RT_Resid ~ Perspective + Valence + Perspective*Valence + (1 + Perspective + Valence | Subject/Passage) +  long_filtered_RT_data)

summary(RT_model)

ER_model <- lmer(ER ~ Perspective + Valence + Perspective*Valence + (1|Subject) + (1|Passage), long_ER_data)

summary(ER_model)

```


The original tables are presented below as Table 1 and Table 2 from Child, Oakhill, & Garnham (2018); the reading times LME model is on the left, and the self-ratings of emotions LME model is on the right.

```{r}
knitr::include_graphics("https://github.com/psych251/child2018/blob/master/original_paper/Child_Oakhill_Garnham_2018_Table1and2.png?raw=true")
```

Below are the tables created in the replication project; the reading times LME model is on the left, and the self-ratings of emotion LME is on the right.

```{r}
###TBD
```


## Discussion

### Summary of Replication Attempt

Open the discussion section with a paragraph summarizing the primary result from the confirmatory analysis and the assessment of whether it replicated, partially replicated, or failed to replicate the original result.  

### Commentary

Add open-ended commentary (if any) reflecting (a) insights from follow-up exploratory analysis, (b) assessment of the meaning of the replication (or not) - e.g., for a failure to replicate, are the differences between original and present study ones that definitely, plausibly, or are unlikely to have been moderators of the result, and (c) discussion of any objections or challenges raised by the current and original authors about the replication attempt.  None of these need to be long.
